#include <vector>
#include <iostream>
#include <fstream>
#include <sstream>
#include <cstdlib>
#include <string>
#include "StatSet.hh"
//#include "cmd_flags.hh"
using namespace std;

//Used in DoGibbsSampling to generate a choice of assignment for current data
//tested by aaa-test-for-Multinomial.cc
int GenerateMultinomial( vector<double> distribution ) {
  double sum_distribution = 0.0;
  for (int i = 0; i < distribution.size(); ++i){
    sum_distribution += distribution[i];
  }
  
  double choice = rand() / static_cast<double>(RAND_MAX) * sum_distribution;
  for (int i = 0; i < distribution.size(); ++i){
    choice -= distribution[i];
    if (choice < 0){
      return i;
    }      
  }
}

//GenerateNewDistributionForData for metagenomic read assignments
void GenerateNewDistributionForData( const DataSet& dataset, 
                                     const StatSet& statset,
                                     int read_index,
                                     int current_assignment,
                                     //bool update_stat,
                                     vector<double>& distribution,
                                     vector<int> alpha )
{  
  int num_assignments = statset.num_assignments();  
  int num_data = statset.num_data();                
  distribution.clear();
  distribution.reserve( num_assignments );
  
  const StatSet::AssignmentDistributionPointer current_assignment_distribution = statset.GetAssignmentDistribution( read_index );   
  
  for ( int i = 0; i < num_assignments; i++ )
  {    
    int current_assignment_adjust = ( i == current_assignment ) ? -1 : 0;
    double assignment_read_factor = current_assignment_distribution[ i ];
    double assignment_allreads_factor = statset.GetGlobalDistribution()[ i ];                                    
    double assignment_factor = dataset.assignment_distributions()[ i ] + current_assignment_adjust;              
    
    //calculate each element of new_distribution phi_i_j * ( n_j_-i + alpha_j ), where phi_i_j = n_(reads same as read i)_j / n_j 
    distribution.push_back( (assignment_read_factor / assignment_allreads_factor) * ( assignment_factor + alpha[i] ));
    
    //
    //cout << "\t" << assignment_read_factor << "\t" << assignment_allreads_factor << "\t" << (assignment_read_factor / assignment_allreads_factor) << "\t" << ( assignment_factor + alpha[i] ) << "\t\t" << (assignment_read_factor / assignment_allreads_factor) * ( assignment_factor + alpha[i] ) << "\n";
  }
  //cout << "\n";
}


//Class DataSet should at least include the data and their assignments (represented by index) that need gibbs sampling and its iterator
//Class StatSet is a class stores the statistics of DataSet needed by gibbs sampling
//Bool update_stat determines whether StatSet would be updated, and Bool burn_in indicates whether this sampling converges
void DoGibbsSampling(DataSet* dataset, StatSet* statset, /*bool update_stat, bool burn_in, */vector<int> alpha ){  //
  
  for ( DataSet::DataOccurrenceIterator iterator(dataset); !iterator.Done(); iterator.Next() ){    
    //the sampling distribution for the current data 
    vector<double> new_distribution;
    //In different applications, GenerateNewDistributionForData may be different, so it need verifying.
    GenerateNewDistributionForData( *dataset, 
                                    *statset,
                                    iterator.Data(), 
                                    iterator.Assignment(), 
                                    //update_stat, 
                                    new_distribution,
                                    alpha );
    
    int new_assignment = GenerateMultinomial( new_distribution );  
     
    if ( new_assignment != -1 )
    {                
      iterator.Reassignment( new_assignment );  
    }        
  }    
}

int main(int argc, char** argv) 
{

  using std::cerr;
  using std::ifstream;
  using std::ofstream;
  using std::istringstream;
  using std::string;
  
  // Command line options
  if ( argc != 3 )
  {
    std::cout << "Arguments needed!!" << "\n"
              << "usage: CoreProbe [input_filename]" << "\n"
              << "input_filename is the file generated by process_bam.py" << "\n"
              << "output_filename is the file generated by CoreProbe" << "\n";
    return 1;
  }  
    
  const char* input_filename = argv[1];
  const char* output_filename = argv[2];
  ///////////////////////////////////////////////////////////////////////////////

  //Set random seed
  srand(time(NULL));

  //Generate DataSet and StatSet using input of precessed SAM/BAM file
  DataSet meta_reads_set( input_filename );
  StatSet meta_reads_stat( meta_reads_set.get_assignments_number(), meta_reads_set.get_data_number() );
  meta_reads_stat.InitiateStat( meta_reads_set );
  meta_reads_set.CondenseInitialData();
  cout << "\nreads count of metagenomic data after condensed:\t" << meta_reads_set.get_data_number() << endl;
  
  //
  //ReadsStat(meta_reads_stat);

  int burn_in_iterations_ = 100;
  int sampling_iterations_ = 10;
  vector<int> alpha_;
  alpha_ = meta_reads_set.get_assignment_alpha();
  
  for (int iter = 0;
       //iter < flags.burn_in_iterations_;
       iter < burn_in_iterations_ + sampling_iterations_;
       ++iter) {
    DoGibbsSampling(&meta_reads_set, &meta_reads_stat, /*true, iter < burn_in_iterations_, */alpha_);
    if ( iter > burn_in_iterations_ && iter < sampling_iterations_ )
    {
      meta_reads_set.AssembleAssignmentDistribution();
    }
  }
  
  meta_reads_set.CalculateAbundance( output_filename );
  
  return 0;
}
